{
  "inputs": [
    {
      "type": "promptString",
      "id": "github_token",
      "description": "GitHub Personal Access Token",
      "password": true
    },
    {
      "type": "promptString",
      "id": "openai_api_key",
      "description": "OpenAI API Key",
      "password": true
    }
  ],
  "servers": {
    "github": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${input:github_token}"
      }
    },
    "my-hello-mcp-server": {
      "type": "stdio",
      "command": "${workspaceFolder}/.venv/bin/fastmcp",
      "args": [
        "run",
        "${workspaceFolder}/src/my_python_ai_kata/mcp/my_hello_server.py"
      ]
    },
    "my-hello-mcp-server-sse": {
      "url": "http://127.0.0.1:8000/sse"
    },
    "my-langgraph_query_tool": {
      "type": "stdio",
      "command": "${workspaceFolder}/.venv/bin/fastmcp",
      "args": [
        "run",
        "${workspaceFolder}/src/my_python_ai_kata/mcp/langgraph_query_tool.py"
      ],
      "env": {
        "OPENAI_API_KEY": "${input:openai_api_key}"
      }
    },
    "my-hello-mcp-server-dockerized": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "scalasmhmh/my-hello-mcp-server:latest"
      ]
    }
  }
}
